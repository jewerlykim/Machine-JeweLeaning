# 합성곱 신경망을 적용한 이미지 분류 사례

## 이론 1

데이터세트 - CIFAR-10
비행기, 개, 개구리, 말, 트럭 등 10개의 클래스
32x32 픽셀의 컬러 이미지
60,000장의 훈련 이미지(6,000장의 클래스당)
CNNs

## 이론 2

합성곱 신경망의 기초

### 1.Convolution(특징 추출 or 특징 검출이라고 불리는 합성곱) Layer

커널 행렬로 주어진 이미지를 스캔하고, 특정한 효과를 얻기 위해 필터를 적용한다.
이미지를 선명하게 만들거나, 이미지의 특징을 강조하는 등의 효과를 얻을 수 있다.
특성 지도가 생성됨(Feature Maps)
픽셀사이의 특별한 상관관계를 유지해주기 때문에 중요하다
픽셀들이 그룹화 되어서 의미가 생긴다.
바로 flatten하면 공간 종속성을 잃어비린다. 신경망의 성능은 나빠진다
그래서 합성곱을 먼저 적용하고 flatten해야한다.

- Live Convolution: http://setosa.io/ev/image-kernels/

### 2.Pooling Layer(Down sampling: 이미지 압축개념) - ReLU 활성화 함수 적용

Pooling Layer를 거치면 32x32 -> 16x16 pixel

### 3.Flatten - 하나의 배열로 만든다.

## 이론 3

특징 검출 후에 적용하는 단계인 ReLU

특징 지도에서 비선형을 더하는데 주로 사용됨.
특징 지도 내부값이 0보다 작으면 0으로 만들어버린다. 0보다 크면 그대로 둔다.
0인 부분은 평평해지고, 꼭지점이 생긴다. -> 신경망과 특징 지도가 분산됨

시그모이드 활성함수와 비교

은닉층에서는 주로 ReLU 함수 사용

ReLU 다음이 풀링 or 다운 샘플링 층

특징 지도의 차원수를 줄임
맥스 풀링을 적용한다
2x2 풀링 적용 => 2X2행렬에서 최대값을 선택함

Live illustration: http://scs.ryerson.ca/~aharley/vis/conv/flat.html

주된 중요한 픽셀에만 집중할 수 잇어서, 오른쪽, 왼쪽에 있는 것이 중요하지 않음
과적합을 방지해서 모델의 일반화를 도와준다.

특정한 위치에 있는 특정한 사람의 얼굴에 대해서만 훈련 받는 것이 아님
flatten 은 2X2 행렬을 1X4 행렬로 만들어줌

## 이론 4

합성곱의 성능 개선 방법과 결과값 보여주는 방식

### 성능 개선 방법

1. 특성 검출 개수를 바꾼다.
   32보다는 64가 더 좋다.
   필터의 수를 더 늘린다.
   코딩으로 간단히 할 수 있음
2. 최근에 발견된 드롭아웃 이라는 방법
   신경망 내의 뉴런 탈락을 의미함.
   일반화라고 불리는 방법
   공동 의존성을 줄여준다.

### 혼동 행렬

분류 결괏값을 나타내는 방법
행은 실제값, 열은 예측값
둘이 +이면 TP (True Positive)
둘이 -이면 TN (True Negative)
실제값이 +인데 예측값이 -이면 FN (False Negative) -> 2종오류(중대한 문제)
실제값이 -인데 예측값이 +이면 FP (False Positive) -> 1종오류

### KPI 핵심 성과 지표 (중요)

분류 정확도 TP+TN/TP+TN+FP+FN
오분류확률,에러확률 FP+FN/TP+TN+FP+FN
정밀도(Precision) TP/TP+FP
재현율(Recall) TP/TP+FN

TP = 1, FP = 1, FN = 8, TN = 90
분류 정확도 = 91/100 = 0.91
오분류확률 = 9/100 = 0.09
정밀도 = 1/2 = 0.5
재현율 = 1/9 = 0.11
분류성과 지표 참고 블로그 [링크](https://sumniya.tistory.com/26)
